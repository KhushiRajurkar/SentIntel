{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6d0890f-8067-4b71-a39a-26ddd87f198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from safetensors.torch import load_file as load_safetensors\n",
    "from transformers import AutoTokenizer, RobertaModel\n",
    "from openvino.runtime import Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e39df7-cfb5-4abb-b601-75ebb38e65e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 1) Your best Safetensors checkpoint ──────────────────────────────────\n",
    "BEST_CKPT = \"goemotions_multilabel_model/checkpoint-10854\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7458adf7-482f-4eb8-8e14-3f36184dfd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from safetensors checkpoint\n"
     ]
    }
   ],
   "source": [
    "# ─── 2) Reconstruct tokenizer + model ─────────────────────────────────────\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "class RobertaForMultiLabel(torch.nn.Module):\n",
    "    def __init__(self, num_labels=28):\n",
    "        super().__init__()\n",
    "        self.roberta    = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "        self.dropout    = torch.nn.Dropout(0.1)\n",
    "        self.classifier = torch.nn.Linear(self.roberta.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        out    = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = self.classifier(self.dropout(out.pooler_output))\n",
    "        loss   = None\n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "            loss     = loss_fct(logits, labels.float())\n",
    "        return {\"loss\": loss, \"logits\": logits}\n",
    "\n",
    "model = RobertaForMultiLabel(num_labels=28)\n",
    "\n",
    "# ─── 2b) Load Safetensors weights ──────────────────────────────────────────\n",
    "safetensors_path = os.path.join(BEST_CKPT, \"model.safetensors\")\n",
    "state_dict        = load_safetensors(safetensors_path, device=\"cpu\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "print(\"Model loaded from safetensors checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6751bbd-c29b-46c7-b027-4adf72d200ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX export complete\n"
     ]
    }
   ],
   "source": [
    "# ─── 3) Export to ONNX ─────────────────────────────────────────────────────\n",
    "dummy = tokenizer(\n",
    "    [\"I am so happy!\", \"This is bad...\"],\n",
    "    padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\"\n",
    ")\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    (dummy[\"input_ids\"], dummy[\"attention_mask\"]),\n",
    "    \"goemotions_multilabel.onnx\",\n",
    "    input_names=[\"input_ids\", \"attention_mask\"],\n",
    "    output_names=[\"logits\"],\n",
    "    dynamic_axes={\n",
    "        \"input_ids\":      {0: \"batch\", 1: \"seq\"},\n",
    "        \"attention_mask\": {0: \"batch\", 1: \"seq\"},\n",
    "        \"logits\":         {0: \"batch\"},\n",
    "    },\n",
    "    opset_version=14,\n",
    ")\n",
    "print(\"ONNX export complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca9c474b-03d6-4cd6-83ad-42d9e612f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 4) Compile with OpenVINO ───────────────────────────────────────────────\n",
    "core     = Core()\n",
    "ov_model = core.read_model(model=\"goemotions_multilabel.onnx\")\n",
    "compiled = core.compile_model(model=ov_model, device_name=\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4975a3bb-743c-449e-b865-1dc2177f6a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28 emotion labels.\n"
     ]
    }
   ],
   "source": [
    "# ─── 5) Hard-coded GoEmotions “simplified” label names ─────────────────────\n",
    "# Copied in the exact order used by the dataset’s ClassLabel\n",
    "emotion_labels = [\n",
    "    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\",\n",
    "    \"confusion\", \"curiosity\", \"desire\", \"disappointment\", \"disapproval\",\n",
    "    \"disgust\", \"embarrassment\", \"excitement\", \"fear\", \"gratitude\", \"grief\",\n",
    "    \"joy\", \"love\", \"nervousness\", \"optimism\", \"pride\", \"realization\", \"relief\",\n",
    "    \"remorse\", \"sadness\", \"surprise\", \"neutral\"\n",
    "]\n",
    "print(f\"Loaded {len(emotion_labels)} emotion labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc202270-718c-4217-af02-9a19ff473fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multi-hot vectors:\n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n",
      "\n",
      "Fired emotions per input:\n",
      "» Input #0 'I am so happy!' fired: ['joy']\n",
      "» Input #1 'This is bad...' fired: ['disappointment', 'disapproval', 'disgust']\n",
      "» Input #2 \"It's not that great but not that bad either\" fired: ['disappointment', 'disapproval', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "# ─── 6) Inference + thresholding + mapping back to names ──────────────────\n",
    "texts = [\"I am so happy!\", \"This is bad...\", \"It's not that great but not that bad either\"]\n",
    "toks  = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"np\")\n",
    "outs  = compiled([toks[\"input_ids\"], toks[\"attention_mask\"]])\n",
    "logits = outs[compiled.output(0)]\n",
    "probs  = 1 / (1 + np.exp(-logits))\n",
    "\n",
    "# choose your operating threshold\n",
    "THR   = 0.3\n",
    "preds = (probs > THR).astype(int)\n",
    "\n",
    "print(\"\\nMulti-hot vectors:\\n\", preds)\n",
    "print(\"\\nFired emotions per input:\")\n",
    "for i, single in enumerate(preds):\n",
    "    fired = [emotion_labels[j] for j, f in enumerate(single) if f]\n",
    "    print(f\"» Input #{i} {texts[i]!r} fired:\", fired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7126b408-eb1a-408e-8301-15d4b8ea282b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenVINO",
   "language": "python",
   "name": "openvino"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
